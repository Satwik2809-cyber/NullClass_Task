Task 1 â€“ Tokenization and Encoding using BERT

1) Objective
This notebook demonstrates tokenization and encoding using HuggingFace's BERT model. It converts text into tokens, encodes them into numerical IDs, and retrieves embeddings.

2) Requirements
- transformers
- torch
- tokenizers

3) Run Instructions
1. Install dependencies:
pip install -r requirements.txt

perl
Copy
Edit

2. Open and run `task1_tokenizer.ipynb` in Jupyter Notebook or Colab.
